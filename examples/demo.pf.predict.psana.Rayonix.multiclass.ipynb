{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185723b5-a7a9-43e1-a4f9-f4c7b2131b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b4849-3627-4b89-b1b0-874843c63f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paths for using psana\n",
    "%env SIT_ROOT=/reg/g/psdm/\n",
    "%env SIT_DATA=/cds/group/psdm/data/\n",
    "%env SIT_PSDM_DATA=/cds/data/psdm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ce2581-cbbc-493e-9626-17217f85aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "from peaknet.methods.unet       import UNet\n",
    "from peaknet.model              import ConfigPeakFinderModel, PeakFinderModel\n",
    "from peaknet.datasets.utils     import PsanaImg\n",
    "from peaknet.datasets.transform import center_crop, coord_crop_to_img\n",
    "\n",
    "from cupyx.scipy import ndimage\n",
    "import cupy as cp\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96383a-31b7-4e1b-ad24-295688442681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors       as mcolors\n",
    "import matplotlib.patches      as mpatches\n",
    "import matplotlib.transforms   as mtransforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b94a84-d502-4476-bccf-74d94606573b",
   "metadata": {},
   "source": [
    "## Load psana for accessing image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efa4ec-370e-4f0d-83d4-8bb3c86a52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Rayonix dataset\n",
    "exp           = 'mfxp22820'\n",
    "run           = 13\n",
    "img_load_mode = 'calib'\n",
    "access_mode   = 'idx'\n",
    "detector_name = 'Rayonix'\n",
    "photon_energy = 9.54e3    # eV\n",
    "encoder_value = -196\n",
    "\n",
    "psana_img = PsanaImg(exp, run, access_mode, detector_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4d5ed-f75f-431a-9ebb-560a61b3c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Rayonix dataset\n",
    "exp           = 'mfx13016'\n",
    "run           = 28\n",
    "img_load_mode = 'calib'\n",
    "access_mode   = 'idx'\n",
    "detector_name = 'Rayonix'\n",
    "# photon_energy = 9.54e3    # eV\n",
    "# encoder_value = -196\n",
    "\n",
    "psana_img = PsanaImg(exp, run, access_mode, detector_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137f07d-a55b-4a81-96d7-d90f581ecaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the global mask...\n",
    "path_mask_gloabl = \"label/global_mask.Rayonix.2023_0328_1117_28.v2.npy\"\n",
    "mask_global = np.load(path_mask_gloabl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bfdcee-3562-4341-ac8d-475bdd6b08f2",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1aa7c6-fb0a-45e2-911b-f303ca141344",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0329_1716_06\"\n",
    "epoch = 225\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725b38c-4683-4cc6-a39f-0cedcd830e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0329_1716_38\"\n",
    "epoch = 192\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474747fe-0e8f-4911-8d3e-7f633b57dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0330_1743_37\"\n",
    "epoch = 196\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399e931-0e9d-4493-8cc3-3453541fbe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0331_1700_54\"\n",
    "epoch = 88\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40951695-4834-4f0a-8642-611a097fd711",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0402_2312_43\"\n",
    "epoch = 118\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec2ca84-54ea-4a7c-8d69-3999168da5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0403_1251_20\"\n",
    "epoch = 58\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88028189-04ef-408b-8d1b-4083f7414dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0403_1219_09\"\n",
    "epoch = 30\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b5d2d-1296-4336-be51-5034fe8557c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0403_1251_20\"\n",
    "epoch = 64\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228dd60e-a7b7-4eec-bb71-17aaf607fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0403_1216_17\"\n",
    "epoch = 131\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de085d51-77b1-4391-a083-facbff65580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0403_1219_09\"\n",
    "epoch = 98\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad0b9b3-c8ca-499f-bf8e-9b5702743b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0403_1300_34\"    # lam = 10.0\n",
    "epoch = 120\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e86e10-7a71-4abb-8d77-50af6afa0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2023_0404_1133_38\"    # lam = 10.0\n",
    "epoch = 154\n",
    "fl_chkpt = None if timestamp is None else f\"{timestamp}.epoch_{epoch}.chkpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa56d0-5651-4f11-b8a2-eaf6585a0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_channels = 8\n",
    "focal_alpha   = 1.2\n",
    "focal_gamma   = 2.0\n",
    "lam = 10.0\n",
    "method = UNet( in_channels = 1, out_channels = 2, base_channels = base_channels )\n",
    "config_peakfinder = ConfigPeakFinderModel( method = method,  \n",
    "                                           focal_alpha = focal_alpha,\n",
    "                                           focal_gamma = focal_gamma,\n",
    "                                           lam = lam, )\n",
    "model = PeakFinderModel(config_peakfinder)\n",
    "model.init_params()    # ..., load random weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9d39f-4348-43e4-bfcb-df0f9091434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.init_params(from_timestamp = timestamp)   # Run this will load a trained model\n",
    "model.init_params(fl_chkpt = fl_chkpt)   # Run this will load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bba487-565b-41f3-956e-09d8f682c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model to gpus if available...\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
    "model  = torch.nn.DataParallel(model.method).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93618e18-0fcf-41b5-a691-ce243e079a4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define hooks (Optional)\n",
    "\n",
    "This is for for printing the metadata of the underlying neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864afb5-69f2-41cd-a325-041dd13375c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hooks...\n",
    "activation_dict = {}\n",
    "preactivation_dict = {}\n",
    "def get_activation(name, tag = ''):\n",
    "    if tag not in preactivation_dict: preactivation_dict[tag] = {}\n",
    "    if tag not in activation_dict: activation_dict[tag] = {}\n",
    "    def hook(model, input, output):\n",
    "        preactivation_dict[tag][name] = input\n",
    "        activation_dict[tag][name] = output\n",
    "    return hook\n",
    "\n",
    "# Define what layer you want to check...\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.ReLU):\n",
    "        layer.register_forward_hook(get_activation(name, 'relu'))\n",
    "\n",
    "    if \"final_conv\" in name:\n",
    "        layer.register_forward_hook(get_activation(name, 'final_conv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c40b0e-2026-4296-bf2f-3a8ba25d003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check out the shape of the output in each layer...\n",
    "# class ReLUShapePrinter:\n",
    "#     def __call__(self, module, input, output):\n",
    "#         if isinstance(module, torch.nn.ReLU):\n",
    "#             print(f\"{module.__class__.__name__} output shape: {output.shape}\")\n",
    "            \n",
    "# # Register the shape printer on each layer\n",
    "# for name, module in model.named_modules():\n",
    "#     module.register_forward_hook(ReLUShapePrinter())\n",
    "            \n",
    "# Check out the shape of the output in each layer...\n",
    "class NonReLUShapePrinter:\n",
    "    def __call__(self, module, input, output):\n",
    "        if not isinstance(module, torch.nn.ReLU):\n",
    "            print(f\"{module.__class__.__name__} output shape: {output.shape}\")\n",
    "\n",
    "# Register the shape printer on each layer\n",
    "for name, module in model.named_modules():\n",
    "    module.register_forward_hook(NonReLUShapePrinter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385cb6d-41df-4925-9f44-585051c6c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d377b-a8d2-4daa-be7b-1e6e8cf430f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of finding peaks in one image (access by event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8f7af-626b-4a6d-b310-e469c4e7e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images by event...\n",
    "# event = 5735\n",
    "# event = 3101\n",
    "event = 1907\n",
    "# event = 7619\n",
    "img   = psana_img.get(event, None, 'calib')\n",
    "\n",
    "# img *= mask_global[0]\n",
    "\n",
    "# img = remove_outliers(img)\n",
    "offset = 10\n",
    "size_y, size_x = img.shape\n",
    "xmin = 0 + offset\n",
    "xmax = size_x - offset\n",
    "ymin = 0 + offset\n",
    "ymax = size_y - offset\n",
    "img = img[ymin:ymax, xmin:xmax]\n",
    "img = torch.tensor(img).type(dtype=torch.float)[None,None,].to(device)\n",
    "img = (img - img.mean()) / img.std()\n",
    "\n",
    "model.eval()\n",
    "time_start = time.monotonic()\n",
    "with torch.no_grad():\n",
    "    fmap = model.forward(img)\n",
    "mask_predicted = fmap.sigmoid()\n",
    "time_end = time.monotonic()\n",
    "print(f\"Elapsed: {(time_end - time_start) * 1e3} ms.\")\n",
    "\n",
    "label_predicted, noise_predicted = mask_predicted[0, :]\n",
    "\n",
    "label_predicted = label_predicted.cpu().detach().numpy()\n",
    "noise_predicted = noise_predicted.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066987f-5b22-4d7f-ae58-2263119cd683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load images by event...\n",
    "# event = 5735\n",
    "# event = 3101\n",
    "event = 1907\n",
    "# event = 7619\n",
    "img   = psana_img.get(event, None, 'calib')\n",
    "\n",
    "# img *= mask_global[0]\n",
    "\n",
    "# img = remove_outliers(img)\n",
    "offset = 10\n",
    "size_y, size_x = img.shape\n",
    "xmin = 0 + offset\n",
    "xmax = size_x - offset\n",
    "ymin = 0 + offset\n",
    "ymax = size_y - offset\n",
    "img = img[ymin:ymax, xmin:xmax]\n",
    "img = torch.tensor(img).type(dtype=torch.float)[None,None,].to(device)\n",
    "img = (img - img.mean()) / img.std()\n",
    "\n",
    "model.eval()\n",
    "time_start = time.monotonic()\n",
    "with torch.no_grad():\n",
    "    fmap = model.forward(img)\n",
    "mask_predicted = fmap.sigmoid()\n",
    "time_end = time.monotonic()\n",
    "print(f\"Elapsed: {(time_end - time_start) * 1e3} ms.\")\n",
    "\n",
    "# label_predicted, noise_predicted, bg_predicted = mask_predicted[0, :]\n",
    "label_predicted, noise_predicted = mask_predicted[0, :]\n",
    "\n",
    "# threshold_prob = 0.5\n",
    "# mask_predicted[  mask_predicted < threshold_prob ] = 0\n",
    "# mask_predicted[~(mask_predicted < threshold_prob)] = 1\n",
    "\n",
    "\n",
    "\n",
    "threshold_prob = 0.2\n",
    "label_predicted[  label_predicted < threshold_prob ] = 0\n",
    "label_predicted[~(label_predicted < threshold_prob)] = 1\n",
    "\n",
    "threshold_prob = 0.4\n",
    "noise_predicted[  noise_predicted < threshold_prob ] = 0\n",
    "noise_predicted[~(noise_predicted < threshold_prob)] = 1\n",
    "\n",
    "label_predicted[noise_predicted > threshold_prob] = 0\n",
    "\n",
    "# threshold_min = 0.5\n",
    "# threshold_max = 0.6\n",
    "# cond = (threshold_min > mask_predicted) + (mask_predicted > threshold_max)\n",
    "# mask_predicted[ cond] = 0\n",
    "# mask_predicted[~cond] = 1\n",
    "\n",
    "# Crop the original image...\n",
    "size_y, size_x = mask_predicted.shape[-2:]\n",
    "img_crop, offset_tuple = center_crop(img, size_y, size_x, returns_offset_tuple = True)\n",
    "\n",
    "img_crop       = img_crop[0, 0].cpu().detach().numpy()\n",
    "# label_predicted, noise_predicted, bg_predicted = mask_predicted[0, :].cpu().detach().numpy()\n",
    "\n",
    "\n",
    "# Locate peaks with coordinates...\n",
    "structure = np.ones((3, 3), dtype=bool)\n",
    "peak_predicted, num_peak_predicted = ndimage.label(cp.asarray(label_predicted), structure)\n",
    "peak_pos_predicted_list = ndimage.center_of_mass(cp.asarray(label_predicted), peak_predicted, cp.asarray(range(1, num_peak_predicted+1)))\n",
    "\n",
    "label_predicted = label_predicted.cpu().detach().numpy()\n",
    "noise_predicted = noise_predicted.cpu().detach().numpy()\n",
    "# bg_predicted    = bg_predicted.cpu().detach().numpy()\n",
    "\n",
    "# [[[ Visual ]]]\n",
    "# Set up the visual\n",
    "ncols = 1\n",
    "nrows = 1\n",
    "fig   = plt.figure(figsize = (16*2,14*2))\n",
    "gspec = fig.add_gridspec( nrows, ncols,\n",
    "                          width_ratios  = [1],\n",
    "                          height_ratios = [1,], \n",
    "                        )\n",
    "ax_list = [ fig.add_subplot(gspec[0, 0], aspect = 1), ]\n",
    "\n",
    "# Plot image\n",
    "data = img_crop\n",
    "vmin = np.mean(data) - 1 * data.std()\n",
    "vmax = np.mean(data) + 6 * data.std()\n",
    "im = ax_list[0].imshow(data, vmin = vmin, vmax = vmax)\n",
    "im.set_clim(vmin, vmax)\n",
    "# plt.colorbar(im, cax = ax_list[1], orientation=\"vertical\", pad = 0.05)\n",
    "\n",
    "# Plot mask overlay\n",
    "data = label_predicted\n",
    "vmin = 0\n",
    "vmax = 1\n",
    "im2 = ax_list[0].imshow(data, vmin = vmin, vmax = vmax, alpha = 1.)\n",
    "im2.set_clim(vmin, vmax)\n",
    "cmap1 = mcolors.ListedColormap(['none', 'red'])\n",
    "im2.set_cmap(cmap1)\n",
    "\n",
    "# Place a box on a peak\n",
    "offset = 4\n",
    "b_offset = 2\n",
    "for y, x in peak_pos_predicted_list:\n",
    "    if np.isnan(y) or np.isnan(x): continue\n",
    "\n",
    "    x_bottom_left = x.get() - offset\n",
    "    y_bottom_left = y.get() - offset\n",
    "\n",
    "    rec_obj = mpatches.Rectangle((x_bottom_left, y_bottom_left),\n",
    "                                 2 * offset, 2 * offset, \n",
    "                                 linewidth = 1.0, \n",
    "                                 edgecolor = 'yellow', \n",
    "                                 facecolor='none')\n",
    "    ax_list[0].add_patch(rec_obj)\n",
    "\n",
    "    y_bmin, x_bmin = 0, 0\n",
    "    y_bmax, x_bmax = size_y, size_x\n",
    "    ax_list[0].set_xlim([x_bmin - b_offset, x_bmax + b_offset])\n",
    "    ax_list[0].set_ylim([y_bmin - b_offset, y_bmax + b_offset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef568111-808e-42a4-90fd-7ad134748f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[[ Visual ]]]\n",
    "# Set up the visual\n",
    "ncols = 1\n",
    "nrows = 1\n",
    "fig   = plt.figure(figsize = (16*1,14*1))\n",
    "gspec = fig.add_gridspec( nrows, ncols,\n",
    "                          width_ratios  = [1],\n",
    "                          height_ratios = [1,], \n",
    "                        )\n",
    "ax_list = [ fig.add_subplot(gspec[0, 0], aspect = 1),  ]\n",
    "\n",
    "# Plot image\n",
    "data = label_predicted\n",
    "vmin = np.mean(data) - 1 * data.std()\n",
    "vmax = np.mean(data) + 6 * data.std()\n",
    "im = ax_list[0].imshow(data, vmin = vmin, vmax = vmax)\n",
    "im.set_clim(vmin, vmax)\n",
    "ax_list[0].set_xlim([x_bmin - b_offset, x_bmax + b_offset])\n",
    "ax_list[0].set_ylim([y_bmin - b_offset, y_bmax + b_offset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f98c8e-3490-4e80-b1d2-4b81950f5c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ Visual ]]]\n",
    "# Set up the visual\n",
    "ncols = 1\n",
    "nrows = 1\n",
    "fig   = plt.figure(figsize = (16*1,14*1))\n",
    "gspec = fig.add_gridspec( nrows, ncols,\n",
    "                          width_ratios  = [1],\n",
    "                          height_ratios = [1,], \n",
    "                        )\n",
    "ax_list = [ fig.add_subplot(gspec[0, 0], aspect = 1),  ]\n",
    "\n",
    "# Plot image\n",
    "data = noise_predicted\n",
    "vmin = np.mean(data) - 1 * data.std()\n",
    "vmax = np.mean(data) + 6 * data.std()\n",
    "im = ax_list[0].imshow(data, vmin = vmin, vmax = vmax)\n",
    "im.set_clim(vmin, vmax)\n",
    "ax_list[0].set_xlim([x_bmin - b_offset, x_bmax + b_offset])\n",
    "ax_list[0].set_ylim([y_bmin - b_offset, y_bmax + b_offset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b921199-6071-4516-ba8c-85a2404ba5f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ Visual ]]]\n",
    "# Set up the visual\n",
    "ncols = 2\n",
    "nrows = 1\n",
    "fig   = plt.figure(figsize = (16*1,14*1))\n",
    "gspec = fig.add_gridspec( nrows, ncols,\n",
    "                          width_ratios  = [1, 1/21],\n",
    "                          height_ratios = [1,], \n",
    "                        )\n",
    "ax_list = [ fig.add_subplot(gspec[0, 0], aspect = 1), fig.add_subplot(gspec[0, 1], box_aspect = 20) ]\n",
    "\n",
    "# Plot image\n",
    "data = bg_predicted\n",
    "im = ax_list[0].imshow(data, vmin = 0, vmax = 1)\n",
    "im.set_clim(vmin, vmax)\n",
    "ax_list[0].set_xlim([x_bmin - b_offset, x_bmax + b_offset])\n",
    "ax_list[0].set_ylim([y_bmin - b_offset, y_bmax + b_offset])\n",
    "fig.colorbar(im, cax = ax_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb14b3-78aa-4a63-b62b-ceb540ed58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[[ Visual ]]]\n",
    "# Set up the visual\n",
    "ncols = 1\n",
    "nrows = 1\n",
    "fig   = plt.figure(figsize = (16*5,14*5))\n",
    "gspec = fig.add_gridspec( nrows, ncols,\n",
    "                          width_ratios  = [1],\n",
    "                          height_ratios = [1,], \n",
    "                        )\n",
    "ax_list = [ fig.add_subplot(gspec[0, 0], aspect = 1), ]\n",
    "\n",
    "# Plot image\n",
    "data = img_crop\n",
    "vmin = np.mean(data) - 1 * data.std()\n",
    "vmax = np.mean(data) + 6 * data.std()\n",
    "im = ax_list[0].imshow(data, vmin = vmin, vmax = vmax)\n",
    "im.set_clim(vmin, vmax)\n",
    "# plt.colorbar(im, cax = ax_list[1], orientation=\"vertical\", pad = 0.05)\n",
    "\n",
    "# Plot mask overlay\n",
    "data = label_predicted\n",
    "vmin = 0\n",
    "vmax = 1\n",
    "im2 = ax_list[0].imshow(data, vmin = vmin, vmax = vmax, alpha = 1.)\n",
    "im2.set_clim(vmin, vmax)\n",
    "cmap1 = mcolors.ListedColormap(['none', 'red'])\n",
    "im2.set_cmap(cmap1)\n",
    "\n",
    "# Plot mask overlay\n",
    "data = noise_predicted\n",
    "vmin = 0\n",
    "vmax = 1\n",
    "im2 = ax_list[0].imshow(data, vmin = vmin, vmax = vmax, alpha = 1.)\n",
    "im2.set_clim(vmin, vmax)\n",
    "cmap1 = mcolors.ListedColormap(['none', 'green'])\n",
    "im2.set_cmap(cmap1)\n",
    "ax_list[0].set_xlim([x_bmin - b_offset, x_bmax + b_offset])\n",
    "ax_list[0].set_ylim([y_bmin - b_offset, y_bmax + b_offset])\n",
    "\n",
    "# Place a box on a peak\n",
    "offset = 4\n",
    "b_offset = 2\n",
    "for y, x in peak_pos_predicted_list:\n",
    "    if np.isnan(y) or np.isnan(x): continue\n",
    "\n",
    "    x_bottom_left = x.get() - offset\n",
    "    y_bottom_left = y.get() - offset\n",
    "\n",
    "    rec_obj = mpatches.Rectangle((x_bottom_left, y_bottom_left), \n",
    "                                 2 * offset, 2 * offset, \n",
    "                                 linewidth = 1.0, \n",
    "                                 edgecolor = 'yellow', \n",
    "                                 facecolor='none')\n",
    "    ax_list[0].add_patch(rec_obj)\n",
    "\n",
    "    y_bmin, x_bmin = 0, 0\n",
    "    y_bmax, x_bmax = size_y, size_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f07c42-a362-4dcd-a8f1-319bc1b54b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ Visual ]]]\n",
    "# Set up the visual\n",
    "ncols = 1\n",
    "nrows = 1\n",
    "fig   = plt.figure(figsize = (16*1,14*1))\n",
    "gspec = fig.add_gridspec( nrows, ncols,\n",
    "                          width_ratios  = [1,],\n",
    "                          height_ratios = [1,], \n",
    "                        )\n",
    "ax_list = [ fig.add_subplot(gspec[0, 0], aspect = 1),  ]\n",
    "\n",
    "# Plot image\n",
    "data = noise_predicted < label_predicted\n",
    "vmin = np.mean(data) - 1 * data.std()\n",
    "vmax = np.mean(data) + 6 * data.std()\n",
    "im = ax_list[0].imshow(data, vmin = vmin, vmax = vmax)\n",
    "# im = ax_list[0].imshow(data, vmin = 0, vmax = 1)\n",
    "# im.set_clim(vmin, vmax)\n",
    "ax_list[0].set_xlim([x_bmin - b_offset, x_bmax + b_offset])\n",
    "ax_list[0].set_ylim([y_bmin - b_offset, y_bmax + b_offset])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4515211-5ff7-43c4-b014-b73a1589a10f",
   "metadata": {},
   "source": [
    "`%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DIVIDER %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%`\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peaknet",
   "language": "python",
   "name": "peaknet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
